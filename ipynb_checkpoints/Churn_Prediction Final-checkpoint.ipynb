{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca03a891",
   "metadata": {},
   "source": [
    "# Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c8ffe4",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71a3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd                  #Importion of libraires\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e92f2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Churn_Modelling.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14556/3838308385.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Churn_Modelling.csv\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Load dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Churn_Modelling.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\") #Load dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334504c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #data information is diplayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6533375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To generate descriptive statistics\n",
    "df.describe() #it describes data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c35e19",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd362a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() #it shows null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcaeb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\" \", np.nan, inplace=True) #if blanks space it will replace with nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() #shows null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78fb2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Surname'], axis = 1,inplace=True) # as its of no use\n",
    "df.drop(['RowNumber'], axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0077e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df[\"Gender\"]) #bar graph for gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c756578",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df[\"Age\"])\n",
    "plt.xticks(rotation=90) #it rotates value of x axis by 90 degrees \n",
    "plt.title(\"Age\") #it is used to title the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['Gender'][df['Exited']==1], data=df) #to show which gender exited the banks services\n",
    "plt.title(\"Exited as per gender\", fontsize=17)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075eb83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({'Geography': df['Geography']}) #it is seprating geography\n",
    "Geography = temp.value_counts()\n",
    "Geography\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= [X[0] for X in Geography.keys()] #getting lables from geography\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01378bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar , ax = plt.subplots(figsize=(18,9))#pie chart for highest number customer as per geographical area\n",
    "ax = plt.pie( x = Geography,autopct = \"%.1f%%\", labels=labels)\n",
    "plt.title('Most Customer',fontsize = 17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaef6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[\"Balance\"])#check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ef09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[\"EstimatedSalary\"])#check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Exited\"].value_counts()#it is calculating count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "lb_make = LabelEncoder() #it helps to convert string value in numeric\n",
    "#here we converted geography and gender in numeric value\n",
    "df['Geography'] = lb_make.fit_transform(df['Geography'])\n",
    "df['Gender'] = lb_make.fit_transform(df['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e032ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.astype(int) #it converts into integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820f385",
   "metadata": {},
   "source": [
    "### Select Training data, test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f18bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the variables as independent and dependent\n",
    "cols=['Exited']\n",
    "\n",
    "X = df.drop(cols, axis = 1) # independent variabes\n",
    "#X = df.drop(['target'], axis = 1)\n",
    "y = df['Exited'] # dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17411cfa",
   "metadata": {},
   "source": [
    "### Feature impotance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8521b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Building the model\n",
    "featimp = ExtraTreesClassifier()\n",
    "\n",
    "# Training the model\n",
    "featimp.fit(X,y)\n",
    "\n",
    "# Computing the importance of each feature\n",
    "featimp.feature_importances_\n",
    "\n",
    "# Plotting a Bar Graph to compare \n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "sns.barplot(x=featimp.feature_importances_, y=X.columns).set(title=\"Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Visualizations/feature_importances.pdf\", dpi=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b8ca53",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df44693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only important features\n",
    "new_df=df.iloc[:,[0,1,2,4,5,6,7,8,9,10,11]]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ee6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select Training data, test data after feature selection\n",
    "X_1= new_df.drop('Exited', axis = 1)\n",
    "y_1 = new_df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #to split data in 80-20\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y_1, test_size = 0.20, random_state=10)#testing ke liye unknown data 20 % rakhna hai \n",
    "#random_state is used to get same data everytime when run\n",
    "#we can give any value in random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For scaling data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0355e068",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c171ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5151f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for accuracy\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.title('Heatmap of Confusion Matrix', fontsize = 15)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm/np.sum(cm), annot = labels ,fmt='', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "dtc = DecisionTreeClassifier(criterion=\"gini\", max_depth = 5)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "dtc = dtc.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = dtc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d4bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for accuracy\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.title('Heatmap of Confusion Matrix', fontsize = 15)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm/np.sum(cm), annot = labels ,fmt='', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f258ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc= RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\n",
    "rfc.fit(X_train, y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979239da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for accuracy\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.title('Heatmap of Confusion Matrix', fontsize = 15)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm/np.sum(cm), annot = labels ,fmt='', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ab2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using random forest as its accuracy is highest \n",
    "import pickle\n",
    "# open a file, where you ant to store the data\n",
    "file = open('model.pkl', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(rfc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for prediction\n",
    "def predict_churn(model,CustomerId,CreditScore,Geography,Age,Tenure,Balance,NumOfProducts,HasCrCard,IsActiveMember,EstimatedSalary):\n",
    "    x =np.zeros(len(X_1.columns)) # create zero numpy array, as input value for model\n",
    "    # adding feature's value accorind to their column index\n",
    "    x[0]=CustomerId\n",
    "    x[1]=CreditScore\n",
    "    x[2]=Geography\n",
    "    x[3]=Age\n",
    "    x[4]=Tenure\n",
    "    x[5]=Balance\n",
    "    x[6]=NumOfProducts\n",
    "    x[7]=HasCrCard\n",
    "    x[8]=IsActiveMember\n",
    "    x[9]=EstimatedSalary\n",
    "    # feature scaling\n",
    "    x = scaler.transform([x])[0] # give 2d np array for feature scaling and get 1d scaled np array\n",
    "    return model.predict([x])[0] # return the predicted value by train Random forest model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87961406",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction 1 ----   Orignal_output = 1 , Predicted_output = 0  ---- model may predict some wrong as our accuracy is 85.6%\n",
    "predict_churn(model=rfc ,CustomerId=15634602,CreditScore=619,Geography=0,Age=42,Tenure=2,Balance=0.0,NumOfProducts=1,HasCrCard=1,IsActiveMember=1,EstimatedSalary=101348.88) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction 2 ----   Orignal_output = 0 , Predicted_output = 0  \n",
    "predict_churn(model=rfc ,CustomerId=15647311,CreditScore=608,Geography=2,Age=41,Tenure=1,Balance=83807.86,NumOfProducts=1,HasCrCard=0,IsActiveMember=1,EstimatedSalary=112542.58) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0365515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction 3 ----   Orignal_output = 1, Predicted_output = 1  \n",
    "predict_churn(model=rfc ,CustomerId=15619304,CreditScore=502,Geography=0,Age=42,Tenure=8,Balance=159660.80,NumOfProducts=3,HasCrCard=1,IsActiveMember=0,EstimatedSalary=113931.57) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7109cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction 4 ----   Orignal_output = 0 , Predicted_output = 0  \n",
    "predict_churn(model=rfc ,CustomerId=15701354,CreditScore=699,Geography=0,Age=39,Tenure=1,Balance=0.0,NumOfProducts=2,HasCrCard=0,IsActiveMember=0,EstimatedSalary=93826.63) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed17954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction 5 ----   Orignal_output = 0 , Predicted_output = 0  \n",
    "predict_churn(model=rfc ,CustomerId=15737888,CreditScore=850,Geography=2,Age=43,Tenure=2,Balance=125510.82,NumOfProducts=1,HasCrCard=1,IsActiveMember=1,EstimatedSalary=79084.10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33145559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction 6 ---- over a random data\n",
    "predict_churn(model=rfc ,CustomerId=15737887,CreditScore=620,Geography=1,Age=22,Tenure=1,Balance=0,NumOfProducts=1,HasCrCard=0,IsActiveMember=0,EstimatedSalary=9084.10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d31b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction 7 ---- over a random data\n",
    "predict_churn(model=rfc ,CustomerId=15737881,CreditScore=220,Geography=1,Age=22,Tenure=1,Balance=0,NumOfProducts=3,HasCrCard=0,IsActiveMember=0,EstimatedSalary=9084.10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6471ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction 8 ---- over a random data\n",
    "predict_churn(model=rfc ,CustomerId=15737882,CreditScore=220,Geography=1,Age=22,Tenure=1,Balance=0,NumOfProducts=3,HasCrCard=0,IsActiveMember=0,EstimatedSalary=900084.10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a4a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
